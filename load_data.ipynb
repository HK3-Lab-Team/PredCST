{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from PredCST.utils.dataset_creation import create_dataset\n",
    "from typing import List, Tuple, Optional\n",
    "import cynde.functional as cf\n",
    "import math\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read the dataset: 17.883113145828247 seconds\n",
      "Time to preprocess the dataset: 5.290783166885376 seconds\n"
     ]
    }
   ],
   "source": [
    "def booleanize_nodes(df: pl.DataFrame, node_columns : List[str]) -> pl.DataFrame:\n",
    "        expression= [pl.col(col) > 0 for col in node_columns]\n",
    "        return df.with_columns(expression)\n",
    "\n",
    "def remove_empty_nodes(df: pl.DataFrame, node_columns: List[str]) -> pl.DataFrame:\n",
    "    zero_cols = [col for col in node_columns if df[col].sum() == 0]\n",
    "    return df.drop(zero_cols), zero_cols\n",
    "# Get the directory above the current directory\n",
    "data_url = r\"C:\\Users\\Tommaso\\Documents\\Dev\\PredCST\\python_3_12_1_standard_lib_all_with_counts.parquet\"\n",
    "# data_url = \"/Users/tommasofurlanello/Documents/Dev/PredCST/python_3_12_1_standard_lib_all_with_counts.parquet\"\n",
    "# dataset_path = os.path.join(cache_dir, dataset_name)\n",
    "start_time = time.time()\n",
    "cynde_dir = os.getenv('CYNDE_DIR')\n",
    "mount_dir = os.getenv('MODAL_MOUNT')\n",
    "df = pl.read_parquet(data_url)\n",
    "df = df.with_row_index()\n",
    "print(f\"Time to read the dataset: {time.time() - start_time} seconds\")\n",
    "start_time = time.time()\n",
    "node_cols = df.columns[13:]\n",
    "df_f = df.filter(pl.col(\"type\") == \"function\").filter(pl.col(\"code_text-embedding-3-small_embedding\").is_not_null())\n",
    "\n",
    "df_fb = booleanize_nodes(df_f, node_cols)\n",
    "df_f_ne, empty_cols = remove_empty_nodes(df_fb, node_cols)\n",
    "\n",
    "print(f\"Time to preprocess the dataset: {time.time() - start_time} seconds\")\n",
    "\n",
    "models_dict = {\"RandomForest\": [{\"n_estimators\": 50, \"max_depth\": 10}]}\n",
    "inputs =[{\"numerical\":[\"code_text-embedding-3-small_embedding\"]},\n",
    "        {\"numerical\":[\"code_text-embedding-3-large_embedding\"]}]\n",
    "\n",
    "# Call the train_nested_cv_from_np function with the required arguments\n",
    "df_f_ne = cf.check_add_cv_index(df_f_ne)\n",
    "target = \"If\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_f_ne\n",
    "cv_type=(\"resample\",\"stratified\")\n",
    "mount_dir=mount_dir\n",
    "inputs=inputs\n",
    "models=models_dict\n",
    "group_outer=[target]\n",
    "k_outer = 5\n",
    "group_inner=[target]\n",
    "k_inner = 5\n",
    "r_outer=1\n",
    "r_inner=1\n",
    "skip_class=False\n",
    "target_column = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_type: resample\n",
      "cv_type: stratified\n",
      "Total rows: 59445\n",
      "Target If rows: 13359\n",
      "Other rows: 46086\n",
      "results schema:  OrderedDict([('classifier', String), ('classifier_hp', String), ('fold_name', String), ('pred_name', String), ('input_features_name', String), ('accuracy_train', Float64), ('accuracy_val', Float64), ('accuracy_test', Float64), ('mcc_train', Float64), ('mcc_val', Float64), ('mcc_test', Float64), ('train_index', List(UInt32)), ('val_index', List(UInt32)), ('test_index', List(UInt32)), ('train_time', String), ('pred_time', String), ('eval_time', String), ('total_cls_time', String), ('k_outer', Int64), ('k_inner', Int64), ('r_outer', Int64), ('r_inner', Int64)])\n",
      "results shape: (0, 22)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = cf.check_add_cv_index(df)\n",
    "pred_df = cf.nested_cv(df, cv_type, group_outer, k_outer, group_inner, k_inner, r_outer, r_inner, return_joined=False)\n",
    "cv_df = df.join(pred_df, on=\"cv_index\", how=\"left\")\n",
    "results_df = pl.DataFrame(schema=cf.RESULTS_SCHEMA)\n",
    "print(\"results schema: \", results_df.schema)\n",
    "print(f\"results shape: {results_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"code_text-embedding-3-large_embedding\"].null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature array shape for code_text-embedding-3-small_embedding: (59445, 1536)\n",
      "Feature array shape for code_text-embedding-3-large_embedding: (59445, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "preprocess_start_time = time.time()\n",
    "feature_arrays, labels, _ = cf.preprocess_dataset(df, inputs, target_column=target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving arrays to C:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cynde_mount\n",
      "Preprocessing completed in 32.64471960067749 seconds\n"
     ]
    }
   ],
   "source": [
    "#save the arrays to cynde_mount folder\n",
    "print(f\"Saving arrays to {mount_dir}\")\n",
    "for feature_name,feature_array in feature_arrays.items():\n",
    "    np.save(os.path.join(mount_dir,feature_name+\".npy\"),feature_array)\n",
    "np.save(os.path.join(mount_dir,\"labels.npy\"),labels)\n",
    "preprocess_end_time = time.time()\n",
    "print(f\"Preprocessing completed in {preprocess_end_time - preprocess_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
